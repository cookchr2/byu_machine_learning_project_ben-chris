{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jan 12 11:34:37 2018\n",
    "\n",
    "@author: cookchr2\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#importing the necessary packages\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "#get the start time\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "#fix random seed for reproducibility\n",
    "seed = 21\n",
    "\n",
    "#This let's numpy use our random seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "#This is the directory \n",
    "os.chdir('R:/JoePriceResearch/record_linking/projects/deep_learning/census')\n",
    "\n",
    "df = pd.read_stata('virpilot_machine_take2dl.dta')\n",
    "\n",
    "df['sort'] = pd.Series(np.random.uniform(size=df.shape[0]))\n",
    "\n",
    "df['m_dist'] = df['distance'] == df['distance'].min()\n",
    "df['m_byr'] = df['poi_birthyear'] == df['poi_birthyear'].min()\n",
    "\n",
    "#df = df.drop(['same_fbpl','same_mbpl'],axis=1)\n",
    "\n",
    "Y = pd.DataFrame()\n",
    "Y['true'] = df['true']\n",
    "Y['false'] = 1 - df['true']\n",
    "Y['sort'] = df['sort']\n",
    "\n",
    "\n",
    "X, Xtest, Y, Ytest = train_test_split(df,Y,test_size = 0.2, random_state=2222)\n",
    "\n",
    "#Surprisingly another hyperparameter! What percentage of the false matches do we keep?\n",
    "Y = Y[(Y.sort >= 0.5) | (Y.true == 1)]\n",
    "X = X[(X.sort >= 0.5) | (X.true == 1)]\n",
    "\n",
    "\n",
    "X = X.drop(['true','sort'], axis=1)\n",
    "Y = Y.drop(['sort'], axis=1)\n",
    "Ytest = Ytest.drop(['sort'], axis=1)\n",
    "Xtest = Xtest.drop(['sort'], axis=1)\n",
    "\n",
    "X['poi_birthyear'] = (X['poi_birthyear'] - df['poi_birthyear'].mean()) /  df['poi_birthyear'].std()\n",
    "Xtest['poi_birthyear'] = (Xtest['poi_birthyear'] - df['poi_birthyear'].mean()) /  df['poi_birthyear'].std()\n",
    "\n",
    "\n",
    "Ytestt = Ytest[(Ytest.true == 1)]\n",
    "Xtestt = Xtest[(Xtest.true == 1)]\n",
    "Ytestf = Ytest[(Ytest.true == 0)]\n",
    "Xtestf = Xtest[(Xtest.true == 0)]\n",
    "\n",
    "Xtestt = Xtestt.drop(['true'], axis=1)\n",
    "Xtestf = Xtestf.drop(['true'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a model\n",
    "model = Sequential([Dense(50, input_dim=48, activation=\"relu\", kernel_initializer='he_normal'),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(25, activation=\"relu\", kernel_initializer='he_normal'),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(12, activation=\"relu\", kernel_initializer='he_normal'),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(6, activation=\"relu\", kernel_initializer='he_normal'),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(3, activation=\"relu\", kernel_initializer='he_normal'),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(0.3),\n",
    "                    Dense(2, activation=\"softmax\", kernel_initializer='he_normal')\n",
    "                    \n",
    "        ])\n",
    "\n",
    "\n",
    "#Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#fit \n",
    "\n",
    "model.fit(X.values, Y.values, epochs=4, batch_size=16,validation_split=0.1)\n",
    "\n",
    "\n",
    "#save the recently trained model\n",
    "\n",
    "model.save('R:/JoePriceResearch/record_linking/projects/deep_learning/census/model21.h5')\n",
    "#evalute\n",
    "\n",
    "#Get a score for true\n",
    "scores = model.evaluate(Xtestt.values, Ytestt.values)\n",
    "print('True %s: %.f%%' % (model.metrics_names[1], scores[1]*1000))\n",
    "\n",
    "\n",
    "scores = model.evaluate(Xtestf.values, Ytestf.values)\n",
    "print('False %s: %.f%%' % (model.metrics_names[1], scores[1]*1000))\n",
    "\n",
    "'''\n",
    "test_predictions = np.argmax(model.predict(Xtest),1)\n",
    "y_test_sparse = np.argmax(Ytest, 1)\n",
    "print(confusion_matrix(y_test_sparse, test_predictions))\n",
    "'''\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(total/60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
